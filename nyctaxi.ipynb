{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask_cudf\n",
    "import distributed\n",
    "import dask_xgboost as dxgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- setting dask settings\n",
      "-- Changes to dask settings\n",
      "--- Setting work-stealing to  False\n",
      "--- Setting scheduler bandwidth to  1\n",
      "-- Settings updates complete\n"
     ]
    }
   ],
   "source": [
    "print(\"- setting dask settings\")\n",
    "dask.config.set({'distributed.scheduler.work-stealing': False})\n",
    "dask.config.set({'distributed.scheduler.bandwidth': 1})\n",
    "\n",
    "print(\"-- Changes to dask settings\")\n",
    "print(\"--- Setting work-stealing to \", dask.config.get('distributed.scheduler.work-stealing'))\n",
    "print(\"--- Setting scheduler bandwidth to \", dask.config.get('distributed.scheduler.bandwidth'))\n",
    "print(\"-- Settings updates complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.0.0.5:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.0.0.5:8787/status' target='_blank'>http://10.0.0.5:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.0.0.5:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = socket.gethostbyname(socket.gethostname())\n",
    "scheduler = \"tcp://\" + ip + \":8786\"\n",
    "client = distributed.Client(scheduler)\n",
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/jobs/ngc_aml_quick_launch_ws/azureml/rapids-exp24-dask_1605803061_87f54d2c/mounts/workspaceblobstore/RAPIDS/notebooks/nyc-taxi/blog_notebooks/azureml/rapids\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update this path by copying the output of the previous cell upto 'workspaceblobstore'\n",
    "datastore = \"/mnt/batch/tasks/shared/LS_root/jobs/ngc_aml_quick_launch_ws/azureml/rapids-exp24-dask_1605803061_87f54d2c/mounts/workspaceblobstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column names that need to be re-mapped\n",
    "remap = {}\n",
    "remap['tpep_pickup_datetime'] = 'pickup_datetime'\n",
    "remap['tpep_dropoff_datetime'] = 'dropoff_datetime'\n",
    "remap['ratecodeid'] = 'rate_code'\n",
    "\n",
    "#create a list of columns & dtypes the df must have\n",
    "must_haves = {\n",
    "    'pickup_datetime': 'datetime64[ms]',\n",
    "    'dropoff_datetime': 'datetime64[ms]',\n",
    "    'passenger_count': 'int32',\n",
    "    'trip_distance': 'float32',\n",
    "    'pickup_longitude': 'float32',\n",
    "    'pickup_latitude': 'float32',\n",
    "    'rate_code': 'int32',\n",
    "    'dropoff_longitude': 'float32',\n",
    "    'dropoff_latitude': 'float32',\n",
    "    'fare_amount': 'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function which takes a DataFrame partition\n",
    "def clean(df_part, remap, must_haves):    \n",
    "    # some col-names include pre-pended spaces remove & lowercase column names\n",
    "    tmp = {col:col.strip().lower() for col in list(df_part.columns)}\n",
    "    df_part = df_part.rename(columns=tmp)\n",
    "    \n",
    "    # rename using the supplied mapping\n",
    "    df_part = df_part.rename(columns=remap)\n",
    "    \n",
    "    # iterate through columns in this df partition\n",
    "    for col in df_part.columns:\n",
    "        # drop anything not in our expected list\n",
    "        if col not in must_haves:\n",
    "            df_part = df_part.drop(columns=col)\n",
    "            continue\n",
    "\n",
    "        if df_part[col].dtype == 'object' and col in ['pickup_datetime', 'dropoff_datetime']:\n",
    "            df_part[col] = df_part[col].astype('datetime64[ms]')\n",
    "            continue\n",
    "            \n",
    "        # if column was read as a string, recast as float\n",
    "        if df_part[col].dtype == 'object':\n",
    "            df_part[col] = df_part[col].str.fillna('-1')\n",
    "            df_part[col] = df_part[col].astype('float32')\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit types\n",
    "            # Tesla T4 are faster on 32bit ops\n",
    "            if 'int' in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype('int32')\n",
    "            if 'float' in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype('float32')\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "    \n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust this dictionary list if you'd like to use different year in this workload\n",
    "is_valid_years = {\n",
    "    \"2014\": False,\n",
    "    \"2015\": False,\n",
    "    \"2016\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(datastore, \"data/nyctaxi\")\n",
    "\n",
    "dfs = []\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"WARNING: the NYC Taxi Trip Data was not found in the Azure datastore\")\n",
    "    print(\"WARNING: updating the data path to use a public datastore\")\n",
    "    print(\"WARNING: data will be downloaded and processed in-situ\")\n",
    "    print(\"WARNING: this degrades performance\")\n",
    "    print(\"WARNING: to avoid this performance degradation, use the `--download_nyctaxi_data=True` option when using start_azureml.py\")\n",
    "    data_path = \"gcs://anaconda-public-data/nyc-taxi/csv/\"\n",
    "    if is_valid_years[\"2014\"]:\n",
    "        taxi_df_2014 = dask_cudf.read_csv(os.path.join(data_path, \"2014/yellow_*.csv\"))\n",
    "        taxi_df_2014 = taxi_df_2014.map_partitions(clean, remap, must_haves)\n",
    "        dfs.append(taxi_df_2014)\n",
    "    if is_valid_years[\"2015\"]:\n",
    "        taxi_df_2015 = dask_cudf.read_csv(os.path.join(data_path, \"2015/yellow_*.csv\"))\n",
    "        taxi_df_2015 = taxi_df_2015.map_partitions(clean, remap, must_haves)\n",
    "        dfs.append(taxi_df_2015)\n",
    "    if is_valid_years[\"2016\"]:\n",
    "        valid_months_2016 = [str(x).rjust(2, '0') for x in range(1, 7)]\n",
    "        valid_files_2016 = [os.path.join(data_path, \"2016/yellow_tripdata_2016-{}.csv\".format(month)) for month in valid_months_2016]\n",
    "        taxi_df_2016 = dask_cudf.read_csv(valid_files_2016)\n",
    "        taxi_df_2016 = taxi_df_2016.map_partitions(clean, remap, must_haves)\n",
    "        dfs.append(taxi_df_2016)\n",
    "else:\n",
    "    if is_valid_years[\"2014\"] and os.path.exists(os.path.join(data_path, \"2014\")):\n",
    "        taxi_df_2014 = dask_cudf.read_csv(os.path.join(data_path, \"2014/yellow_*.csv\"))\n",
    "        taxi_df_2014 = taxi_df_2014.map_partitions(clean, remap, must_haves)\n",
    "        dfs.append(taxi_df_2014)\n",
    "    if is_valid_years[\"2015\"] and os.path.exists(os.path.join(data_path, \"2014\")):\n",
    "        taxi_df_2015 = dask_cudf.read_csv(os.path.join(data_path, \"2015/yellow_*.csv\"))\n",
    "        taxi_df_2015 = taxi_df_2015.map_partitions(clean, remap, must_haves)\n",
    "        dfs.append(taxi_df_2015)\n",
    "    if is_valid_years[\"2016\"] and os.path.exists(os.path.join(data_path, \"2014\")):\n",
    "        taxi_df_2016 = dask_cudf.read_csv(os.path.join(data_path, \"2016/yellow_*.csv\"))\n",
    "        #The use of the commented line below throws an error related the bad formatted dates. Running the clean function directly works\n",
    "        #taxi_df_2016 = taxi_df_2016.map_partitions(clean, remap, must_haves)\n",
    "        taxi_df_2016 = clean(taxi_df_2016, remap, must_haves)\n",
    "        dfs.append(taxi_df_2016)\n",
    "\n",
    "taxi_df = dask.dataframe.multi.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are as follows:\n",
      "pickup_datetime\n",
      "dropoff_datetime\n",
      "passenger_count\n",
      "trip_distance\n",
      "pickup_longitude\n",
      "pickup_latitude\n",
      "rate_code\n",
      "dropoff_longitude\n",
      "dropoff_latitude\n",
      "fare_amount\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names are as follows:\")\n",
    "for column in taxi_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-73.990372</td>\n",
       "      <td>40.734695</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.981842</td>\n",
       "      <td>40.732407</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-73.980782</td>\n",
       "      <td>40.729912</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.944473</td>\n",
       "      <td>40.716679</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10.54</td>\n",
       "      <td>-73.984550</td>\n",
       "      <td>40.679565</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.950272</td>\n",
       "      <td>40.788925</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-73.993469</td>\n",
       "      <td>40.718990</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.962242</td>\n",
       "      <td>40.657333</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-73.960625</td>\n",
       "      <td>40.781330</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.977264</td>\n",
       "      <td>40.758514</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pickup_datetime dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0      2016-01-01       2016-01-01                2           1.10   \n",
       "1      2016-01-01       2016-01-01                5           4.90   \n",
       "2      2016-01-01       2016-01-01                1          10.54   \n",
       "3      2016-01-01       2016-01-01                1           4.75   \n",
       "4      2016-01-01       2016-01-01                3           1.76   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  rate_code  dropoff_longitude  \\\n",
       "0        -73.990372        40.734695          1         -73.981842   \n",
       "1        -73.980782        40.729912          1         -73.944473   \n",
       "2        -73.984550        40.679565          1         -73.950272   \n",
       "3        -73.993469        40.718990          1         -73.962242   \n",
       "4        -73.960625        40.781330          1         -73.977264   \n",
       "\n",
       "   dropoff_latitude  fare_amount  \n",
       "0         40.732407          7.5  \n",
       "1         40.716679         18.0  \n",
       "2         40.788925         33.0  \n",
       "3         40.657333         16.5  \n",
       "4         40.758514          8.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a list of filter conditions to throw out records with missing or outlier values\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "\n",
    "# inspect the results of cleaning\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import cos, sin, asin, sqrt, pi\n",
    "import numpy as np\n",
    "\n",
    "def haversine_distance_kernel(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, h_distance):\n",
    "    for i, (x_1, y_1, x_2, y_2) in enumerate(zip(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)):\n",
    "        x_1 = pi / 180 * x_1\n",
    "        y_1 = pi / 180 * y_1\n",
    "        x_2 = pi / 180 * x_2\n",
    "        y_2 = pi / 180 * y_2\n",
    "        \n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat / 2)**2 + cos(x_1) * cos(x_2) * sin(dlon / 2)**2\n",
    "        \n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        \n",
    "        h_distance[i] = c * r\n",
    "\n",
    "def day_of_the_week_kernel(day, month, year, day_of_week):\n",
    "    for i, (d_1, m_1, y_1) in enumerate(zip(day, month, year)):\n",
    "        if month[i] < 3:\n",
    "            shift = month[i]\n",
    "        else:\n",
    "            shift = 0\n",
    "        Y = year[i] - (month[i] < 3)\n",
    "        y = Y - 2000\n",
    "        c = 20\n",
    "        d = day[i]\n",
    "        m = month[i] + shift + 1\n",
    "        day_of_week[i] = (d + math.floor(m * 2.6) + y + (y // 4) + (c // 4) - 2 * c) % 7\n",
    "        \n",
    "def add_features(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    df['diff'] = df['dropoff_datetime'].astype('int32') - df['pickup_datetime'].astype('int32')\n",
    "    \n",
    "    df['pickup_latitude_r'] = df['pickup_latitude'] // .01 * .01\n",
    "    df['pickup_longitude_r'] = df['pickup_longitude'] // .01 * .01\n",
    "    df['dropoff_latitude_r'] = df['dropoff_latitude'] // .01 * .01\n",
    "    df['dropoff_longitude_r'] = df['dropoff_longitude'] // .01 * .01\n",
    "    \n",
    "    df = df.drop(columns='pickup_datetime')\n",
    "    df = df.drop(columns='dropoff_datetime')\n",
    "\n",
    "    df = df.apply_rows(haversine_distance_kernel,\n",
    "                       incols=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'],\n",
    "                       outcols=dict(h_distance=np.float32),\n",
    "                       kwargs=dict())\n",
    "\n",
    "    df = df.apply_rows(day_of_the_week_kernel,\n",
    "                       incols=['day', 'month', 'year'],\n",
    "                       outcols=dict(day_of_week=np.float32),\n",
    "                       kwargs=dict())\n",
    "\n",
    "\n",
    "    df['is_weekend'] = (df['day_of_week']<2).astype(\"int32\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# actually add the features\n",
    "taxi_df = taxi_df.map_partitions(add_features).persist()\n",
    "done = distributed.wait(taxi_df)\n",
    "# inspect the result\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "taxi_df.groupby('hour').fare_amount.mean().compute().to_pandas().sort_index().plot(legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train = taxi_df.query('day < 25').persist()\n",
    "\n",
    "# create a Y_train ddf with just the target variable\n",
    "Y_train = X_train[['fare_amount']].persist()\n",
    "# drop the target variable from the training ddf\n",
    "X_train = X_train[X_train.columns.difference(['fare_amount'])]\n",
    "\n",
    "# this wont return until all data is in GPU memory\n",
    "done = distributed.wait([X_train, Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'learning_rate'  : 0.3,\n",
    "    'max_depth'      : 8,\n",
    "    'objective'      : 'reg:squarederror',\n",
    "    'subsample'      : 0.6,\n",
    "    'gamma'          : 1,\n",
    "    'silent'         : True,\n",
    "    'verbose_eval'   : True,\n",
    "    'tree_method'    :'gpu_hist'\n",
    "}\n",
    "\n",
    "##This line is throwing an error\n",
    "trained_model = dxgb.train(client, params, X_train, Y_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_partitions(df):\n",
    "    lengths = df.map_partitions(len).compute()\n",
    "    nonempty = [length > 0 for length in lengths]\n",
    "    return df.partitions[nonempty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = taxi_df.query('day >= 25').persist()\n",
    "X_test = drop_empty_partitions(X_test)\n",
    "\n",
    "# Create Y_test with just the fare amount\n",
    "Y_test = X_test[['fare_amount']]\n",
    "\n",
    "# Drop the fare amount from X_test\n",
    "X_test = X_test[X_test.columns.difference(['fare_amount'])]\n",
    "\n",
    "# display test set size\n",
    "# len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions on the test set\n",
    "\n",
    "Y_test['prediction'] = dxgb.predict(client, trained_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test['squared_error'] = (Y_test['prediction'] - Y_test['fare_amount'])**2\n",
    "\n",
    "# inspect the results to make sure our calculation looks right\n",
    "Y_test.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the actual RMSE over the full test set\n",
    "RMSE = Y_test.squared_error.mean().compute()\n",
    "math.sqrt(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
